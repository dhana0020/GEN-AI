{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zfvNqZlQ6O7S",
        "outputId": "cf29fda0-9f12-4734-e67f-99c01bc85f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8096ac4d4505a09f71.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8096ac4d4505a09f71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install openai\n",
        "\n",
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def chatbot_response(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=gr.Textbox(placeholder=\"Ask me anything...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Chatbot\",\n",
        "    description=\"An interactive chatbot powered by OpenAI's GPT model.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def chatbot_response(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=gr.Textbox(placeholder=\"Ask me anything...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Chatbot\",\n",
        "    description=\"An interactive chatbot powered by OpenAI's GPT-4 model.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "z4ynoL-i6Uof",
        "outputId": "bdbf598f-0a53-41a6-c182-e44c2e1fe877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ac8f9f7db00688443f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ac8f9f7db00688443f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Chatbot: Hello! Type 'exit' to stop the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": user_input}]\n",
        "            )\n",
        "            chatbot_reply = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "            print(f\"Chatbot: {chatbot_reply}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwzvj5HW61ZO",
        "outputId": "f4415860-d1a6-4666-ad3a-90ca72c7ee6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! Type 'exit' to stop the conversation.\n",
            "\n",
            "You: helooooooo\n",
            "Error: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "import requests\n",
        "\n",
        "# Set your Router AI API key\n",
        "API_KEY = \"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\"\n",
        "ENDPOINT = \"https://api.router.ai/v1/chat/completions\"\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Chatbot: Hello! Type 'exit' to stop the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        data = {\n",
        "            \"model\": \"gpt-4\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(ENDPOINT, json=data, headers=headers)\n",
        "            response_json = response.json()\n",
        "\n",
        "            if \"choices\" in response_json:\n",
        "                chatbot_reply = response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "                print(f\"Chatbot: {chatbot_reply}\\n\")\n",
        "            else:\n",
        "                print(f\"Error: {response_json}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "l3RuvrWt7MvT",
        "outputId": "41f19b1f-0f38-4c26-dcf8-a3158428b7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Chatbot: Hello! Type 'exit' to stop the conversation.\n",
            "\n",
            "You: helo\n",
            "Error: HTTPSConnectionPool(host='api.router.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7c0b0f29da10>: Failed to resolve 'api.router.ai' ([Errno -2] Name or service not known)\"))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0bdd90eaca91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Run the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-0bdd90eaca91>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your API key\n",
        "openai.api_key = \"your_openai_api_key_here\"\n",
        "\n",
        "# Chat function\n",
        "def chat():\n",
        "    print(\"Chatbot: Hello! Type 'exit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # API request (no need to specify an endpoint)\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": user_input}]\n",
        "        )\n",
        "\n",
        "        # Print chatbot response\n",
        "        chatbot_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        print(f\"Chatbot: {chatbot_reply}\\n\")\n",
        "\n",
        "# Start chatbot\n",
        "chat()\n"
      ],
      "metadata": {
        "id": "DcwmFOnE7ucz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# ✅ Replace with your actual API key\n",
        "API_KEY = \"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\"\n",
        "\n",
        "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"HTTP-Referer\": \"your_project_name\",  # Required for OpenRouter\n",
        "    \"X-Title\": \"API Key Test\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"openrouter/gpt-4\",  # Change model if needed\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, are you working?\"}]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"✅ API Key is VALID!\")\n",
        "    print(\"Response:\", response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
        "else:\n",
        "    print(\"❌ API Key is INVALID or has issues!\")\n",
        "    print(\"Error:\", response.json())\n"
      ],
      "metadata": {
        "id": "aNOfRZh2946w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Configuration\n",
        "API_KEY = \"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\"\n",
        "MODEL = \"openai/gpt-3.5-turbo\"  # or any other model from OpenRouter\n",
        "\n",
        "def chat_with_openrouter(prompt, history=[]):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    messages = history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    data = {\n",
        "        \"model\": MODEL,\n",
        "        \"messages\": messages\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(data)\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"Error: {response.status_code} - {response.text}\"\n",
        "\n",
        "# Simple chat loop\n",
        "chat_history = []\n",
        "print(\"Chatbot ready! Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    response = chat_with_openrouter(user_input, chat_history)\n",
        "    print(f\"Bot: {response}\")\n",
        "\n",
        "    # Update chat history (optional, be mindful of token limits)\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "E-wf339Y99Y_",
        "outputId": "b7ced46f-4d01-4682-839d-de816fa604c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready! Type 'quit' to exit.\n",
            "You: hi\n",
            "Bot: Error: 402 - {\"error\":{\"message\":\"Insufficient credits. Add more using https://openrouter.ai/settings/credits\",\"code\":402}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-da93e2ae8c4c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot ready! Type 'quit' to exit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "API_KEY = \"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\"\n",
        "MODEL = \"google/palm-2-chat-bison\"  # Using a free model\n",
        "\n",
        "def chat_with_openrouter(prompt, history=[]):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    messages = history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    data = {\n",
        "        \"model\": MODEL,\n",
        "        \"messages\": messages\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            data=json.dumps(data),\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        else:\n",
        "            error_msg = response.json().get(\"error\", {}).get(\"message\", \"Unknown error\")\n",
        "            return f\"API Error {response.status_code}: {error_msg}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Connection error: {str(e)}\"\n",
        "\n",
        "# Chat loop\n",
        "chat_history = []\n",
        "print(\"Chatbot ready! Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['quit', 'exit']:\n",
        "        break\n",
        "\n",
        "    response = chat_with_openrouter(user_input, chat_history)\n",
        "    print(f\"Bot: {response}\")\n",
        "\n",
        "    # Optional: Update chat history (keep it short to avoid token limits)\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "    chat_history = chat_history[-6:]  # Keep last 3 exchanges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "bKcblSE0-6um",
        "outputId": "707fb509-46fb-46f6-fb15-ba4ddfd250f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready! Type 'quit' to exit.\n",
            "You: hi\n",
            "Bot: API Error 402: Insufficient credits. Add more using https://openrouter.ai/settings/credits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0e40a1b30d17>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot ready! Type 'quit' to exit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"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\"\n",
        "MODEL = \"google/palm-2-chat-bison\"  # Free model\n",
        "\n",
        "def chat_with_palm(prompt):\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": MODEL,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(\"Free Palm-2 Chatbot (type 'quit' to exit)\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['quit', 'exit']: break\n",
        "    print(\"Bot:\", chat_with_palm(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "g3Dq2E35_Y_c",
        "outputId": "e3431ca3-56c3-4baf-e72f-7b103cea501f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Free Palm-2 Chatbot (type 'quit' to exit)\n",
            "You: hi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'choices'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b803af9059ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bot:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_with_palm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-b803af9059ef>\u001b[0m in \u001b[0;36mchat_with_palm\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Free Palm-2 Chatbot (type 'quit' to exit)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'choices'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"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\"\n",
        "MODEL = \"google/palm-2-chat-bison\"  # Free model\n",
        "\n",
        "def chat_with_palm(prompt):\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"HTTP-Referer\": \"https://your-site-url.com\",  # Required for free models\n",
        "                \"X-Title\": \"Your App Name\"  # Required for free models\n",
        "            },\n",
        "            json={\n",
        "                \"model\": MODEL,\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "            },\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        response_data = response.json()\n",
        "\n",
        "        # Debug print to see actual response\n",
        "        print(\"DEBUG - Full API Response:\", response_data)\n",
        "\n",
        "        if \"choices\" in response_data:\n",
        "            return response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "        elif \"error\" in response_data:\n",
        "            return f\"API Error: {response_data['error']['message']}\"\n",
        "        else:\n",
        "            return \"Unexpected API response format\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Request failed: {str(e)}\"\n",
        "\n",
        "print(\"Free Palm-2 Chatbot (type 'quit' to exit)\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['quit', 'exit']:\n",
        "        break\n",
        "    response = chat_with_palm(user_input)\n",
        "    print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Z5hKILSkALML",
        "outputId": "7078a4b5-d3c0-442d-84dd-c7d58d379332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free Palm-2 Chatbot (type 'quit' to exit)\n",
            "You: hi\n",
            "DEBUG - Full API Response: {'error': {'message': 'Insufficient credits. Add more using https://openrouter.ai/settings/credits', 'code': 402}}\n",
            "Bot: API Error: Insufficient credits. Add more using https://openrouter.ai/settings/credits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-258dc157254f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Free Palm-2 Chatbot (type 'quit' to exit)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\n",
        "    \"https://openrouter.ai/api/v1/auth/key\",\n",
        "    headers={\"Authorization\": \"Bearer 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\"}\n",
        ")\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmWEyy-kAqNJ",
        "outputId": "50fcc1b1-c0d1-49df-fcb4-dff4b186c780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': {'label': 'sk-or-v1-ba6...a40', 'limit': None, 'usage': 0, 'is_provisioning_key': False, 'limit_remaining': None, 'is_free_tier': True, 'rate_limit': {'requests': 10, 'interval': '10s'}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class FreeOpenRouterChatbot:\n",
        "    def __init__(self):\n",
        "        self.API_KEY = \"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\"  # Your API key\n",
        "        self.MODEL = \"huggingfaceh4/zephyr-7b-beta\"  # Reliable free model\n",
        "        self.rate_limit = deque(maxlen=10)  # Track last 10 requests (10/10s limit)\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        # Handle rate limiting\n",
        "        now = time.time()\n",
        "        while len(self.rate_limit) >= 10 and now - self.rate_limit[0] < 10:\n",
        "            time.sleep(0.1)\n",
        "            now = time.time()\n",
        "\n",
        "        try:\n",
        "            self.rate_limit.append(now)\n",
        "\n",
        "            response = requests.post(\n",
        "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                headers={\n",
        "                    \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                    \"HTTP-Referer\": \"https://localhost:3000\",\n",
        "                    \"X-Title\": \"Free Chatbot\"\n",
        "                },\n",
        "                json={\n",
        "                    \"model\": self.MODEL,\n",
        "                    \"messages\": self.conversation_history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "                },\n",
        "                timeout=15\n",
        "            )\n",
        "\n",
        "            data = response.json()\n",
        "            if \"choices\" in data:\n",
        "                reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
        "                self.conversation_history.extend([\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                    {\"role\": \"assistant\", \"content\": reply}\n",
        "                ])\n",
        "                return reply\n",
        "            return f\"API Error: {data.get('error', {}).get('message', 'Unknown error')}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Request failed: {str(e)}\"\n",
        "\n",
        "# Usage\n",
        "bot = FreeOpenRouterChatbot()\n",
        "print(\"Free OpenRouter Chatbot (type 'quit' to exit)\")\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "        print(\"Bot:\", bot.chat(user_input))\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2nNZx2TA_4Z",
        "outputId": "99d9d0cc-aca8-45bc-c78a-615fee42794b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free OpenRouter Chatbot (type 'quit' to exit)\n",
            "You: hi\n",
            "Bot: API Error: No endpoints found for huggingfaceh4/zephyr-7b-beta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class FreeOpenRouterChatbot:\n",
        "    def __init__(self):\n",
        "        self.API_KEY =\"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\" # Your API key\n",
        "        self.FREE_MODELS = [\n",
        "            \"meta-llama/llama-2-13b-chat\",   # Most reliable free option\n",
        "            \"mancer/weaver\",                  # Good alternative\n",
        "            \"gryphe/mythomax-l2-13b\",        # Sometimes available\n",
        "            \"anthropic/claude-instant-v1\",    # Free tier available\n",
        "            \"google/palm-2-chat-bison\"       # Fallback option\n",
        "        ]\n",
        "        self.current_model_index = 0\n",
        "        self.rate_limit = deque(maxlen=10)  # 10 requests per 10s\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def get_current_model(self):\n",
        "        return self.FREE_MODELS[self.current_model_index]\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        # Handle rate limiting\n",
        "        now = time.time()\n",
        "        while len(self.rate_limit) >= 10 and now - self.rate_limit[0] < 10:\n",
        "            time.sleep(0.1)\n",
        "            now = time.time()\n",
        "\n",
        "        try:\n",
        "            self.rate_limit.append(now)\n",
        "\n",
        "            response = requests.post(\n",
        "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                headers={\n",
        "                    \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                    \"HTTP-Referer\": \"https://localhost:3000\",\n",
        "                    \"X-Title\": \"Free Chatbot\"\n",
        "                },\n",
        "                json={\n",
        "                    \"model\": self.get_current_model(),\n",
        "                    \"messages\": self.conversation_history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "                },\n",
        "                timeout=15\n",
        "            )\n",
        "\n",
        "            data = response.json()\n",
        "\n",
        "            if \"choices\" in data:\n",
        "                reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
        "                self.conversation_history.extend([\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                    {\"role\": \"assistant\", \"content\": reply}\n",
        "                ])\n",
        "                return reply\n",
        "            else:\n",
        "                # Try next model if current one fails\n",
        "                error_msg = data.get('error', {}).get('message', 'Unknown error')\n",
        "                if self.current_model_index < len(self.FREE_MODELS) - 1:\n",
        "                    self.current_model_index += 1\n",
        "                    print(f\"Switching to model: {self.get_current_model()}\")\n",
        "                    return self.chat(prompt)  # Retry with new model\n",
        "                return f\"API Error: {error_msg}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Request failed: {str(e)}\"\n",
        "\n",
        "# Usage\n",
        "bot = FreeOpenRouterChatbot()\n",
        "print(f\"Free OpenRouter Chatbot (using {bot.get_current_model()})\")\n",
        "print(\"Type 'quit' to exit\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "        print(\"Bot:\", bot.chat(user_input))\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_vRwYePBaRQ",
        "outputId": "0d2e8361-b2c0-42cd-902d-2f5e9dfadf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free OpenRouter Chatbot (using meta-llama/llama-2-13b-chat)\n",
            "Type 'quit' to exit\n",
            "You: hi\n",
            "Switching to model: mancer/weaver\n",
            "Switching to model: gryphe/mythomax-l2-13b\n",
            "Switching to model: anthropic/claude-instant-v1\n",
            "Switching to model: google/palm-2-chat-bison\n",
            "Bot: API Error: Insufficient credits. Add more using https://openrouter.ai/settings/credits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class FreeChatbot:\n",
        "    def __init__(self):\n",
        "        self.API_KEY = \"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\"  # Replace with your key\n",
        "        self.FREE_MODELS = self.get_available_free_models()\n",
        "        self.current_model_index = 0\n",
        "        self.rate_limit = deque(maxlen=10)  # 10 requests per 10s\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def get_available_free_models(self):\n",
        "        \"\"\"Check which models are actually available for free right now\"\"\"\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                \"https://openrouter.ai/api/v1/models\",\n",
        "                headers={\"Authorization\": f\"Bearer {self.API_KEY}\"}\n",
        "            )\n",
        "            models = response.json().get('data', [])\n",
        "\n",
        "            # Filter models that are free and currently available\n",
        "            return [\n",
        "                model['id'] for model in models\n",
        "                if model.get('pricing', {}).get('prompt') == \"0\"\n",
        "                and not model.get('disabled', True)\n",
        "            ][:5]  # Return top 5 available free models\n",
        "\n",
        "        except:\n",
        "            # Fallback list if API call fails\n",
        "            return [\n",
        "                \"meta-llama/llama-2-13b-chat\",\n",
        "                \"huggingfaceh4/zephyr-7b-beta\",\n",
        "                \"mancer/weaver\",\n",
        "                \"gryphe/mythomax-l2-13b\",\n",
        "                \"google/palm-2-chat-bison\"\n",
        "            ]\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        if not self.FREE_MODELS:\n",
        "            return \"Error: No free models currently available\"\n",
        "\n",
        "        # Try each model until we get a response\n",
        "        for i in range(len(self.FREE_MODELS)):\n",
        "            model = self.FREE_MODELS[self.current_model_index]\n",
        "\n",
        "            try:\n",
        "                # Handle rate limiting\n",
        "                now = time.time()\n",
        "                while len(self.rate_limit) >= 10 and now - self.rate_limit[0] < 10:\n",
        "                    time.sleep(0.5)\n",
        "                    now = time.time()\n",
        "\n",
        "                self.rate_limit.append(now)\n",
        "\n",
        "                response = requests.post(\n",
        "                    \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                    headers={\n",
        "                        \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                        \"HTTP-Referer\": \"https://localhost:3000\",\n",
        "                        \"X-Title\": \"Free Chatbot\"\n",
        "                    },\n",
        "                    json={\n",
        "                        \"model\": model,\n",
        "                        \"messages\": self.conversation_history + [{\"role\": \"user\", \"content\": prompt}]\n",
        "                    },\n",
        "                    timeout=20\n",
        "                )\n",
        "\n",
        "                data = response.json()\n",
        "\n",
        "                if \"choices\" in data:\n",
        "                    reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
        "                    self.conversation_history.extend([\n",
        "                        {\"role\": \"user\", \"content\": prompt},\n",
        "                        {\"role\": \"assistant\", \"content\": reply}\n",
        "                    ])\n",
        "                    return reply\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {model}: {str(e)}\")\n",
        "\n",
        "            # Cycle to next model\n",
        "            self.current_model_index = (self.current_model_index + 1) % len(self.FREE_MODELS)\n",
        "\n",
        "        return \"Sorry, all free models are currently unavailable. Please try again later.\"\n",
        "\n",
        "# Usage\n",
        "bot = FreeChatbot()\n",
        "print(\"Free Chatbot - Type 'quit' to exit\")\n",
        "print(f\"Available models: {', '.join(bot.FREE_MODELS)}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        response = bot.chat(user_input)\n",
        "        print(f\"Bot ({bot.FREE_MODELS[bot.current_model_index]}): {response}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "SM_7FTIYBy3o",
        "outputId": "673c010f-b689-455a-a14b-76462ba9531f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Free Chatbot - Type 'quit' to exit\n",
            "Available models: \n",
            "You: hi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-984861544c7e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bot ({bot.FREE_MODELS[bot.current_model_index]}): {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class FreeChatbot:\n",
        "    def __init__(self):\n",
        "        self.API_KEY = \"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\"  # Replace with your key\n",
        "        self.FREE_MODELS = self.get_available_free_models()\n",
        "        self.current_model_index = 0 if self.FREE_MODELS else -1\n",
        "        self.rate_limit = deque(maxlen=10)  # 10 requests per 10s\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def get_available_free_models(self):\n",
        "        \"\"\"Get currently available free models with fallback\"\"\"\n",
        "        try:\n",
        "            response = requests.get(\n",
        "                \"https://openrouter.ai/api/v1/models\",\n",
        "                headers={\"Authorization\": f\"Bearer {self.API_KEY}\"},\n",
        "                timeout=10\n",
        "            )\n",
        "            models = response.json().get('data', [])\n",
        "\n",
        "            available = [\n",
        "                model['id'] for model in models\n",
        "                if model.get('pricing', {}).get('prompt') == \"0\"\n",
        "                and not model.get('disabled', True)\n",
        "            ]\n",
        "\n",
        "            return available or [\n",
        "                \"meta-llama/llama-2-13b-chat\",\n",
        "                \"huggingfaceh4/zephyr-7b-beta\",\n",
        "                \"mancer/weaver\",\n",
        "                \"google/palm-2-chat-bison\"\n",
        "            ]\n",
        "\n",
        "        except:\n",
        "            return []  # Will use local fallback\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        # Local fallback if no models available\n",
        "        if not self.FREE_MODELS:\n",
        "            return self.local_fallback(prompt)\n",
        "\n",
        "        try:\n",
        "            # Handle rate limiting\n",
        "            now = time.time()\n",
        "            while len(self.rate_limit) >= 10 and now - self.rate_limit[0] < 10:\n",
        "                time.sleep(0.5)\n",
        "                now = time.time()\n",
        "\n",
        "            self.rate_limit.append(now)\n",
        "\n",
        "            response = requests.post(\n",
        "                \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                headers={\n",
        "                    \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                    \"HTTP-Referer\": \"https://localhost:3000\",\n",
        "                    \"X-Title\": \"Free Chatbot\"\n",
        "                },\n",
        "                json={\n",
        "                    \"model\": self.FREE_MODELS[self.current_model_index],\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "                },\n",
        "                timeout=20\n",
        "            )\n",
        "\n",
        "            data = response.json()\n",
        "\n",
        "            if \"choices\" in data:\n",
        "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "            return f\"API Error: {data.get('error', {}).get('message', 'Unknown error')}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Request failed: {str(e)}\"\n",
        "\n",
        "    def local_fallback(self, prompt):\n",
        "        \"\"\"Simple local responses when API isn't available\"\"\"\n",
        "        responses = {\n",
        "            \"hi\": \"Hello! I'm using a local fallback right now.\",\n",
        "            \"hello\": \"Hi there! The free models seem unavailable currently.\",\n",
        "            \"how are you\": \"I'm running locally since the AI services are down\",\n",
        "            \"quit\": \"Goodbye!\",\n",
        "            \"exit\": \"See you later!\"\n",
        "        }\n",
        "        return responses.get(prompt.lower(),\n",
        "               \"I can only give simple responses right now. Try asking 'hi' or 'hello'.\")\n",
        "\n",
        "# Usage\n",
        "print(\"Initializing chatbot...\")\n",
        "bot = FreeChatbot()\n",
        "\n",
        "if not bot.FREE_MODELS:\n",
        "    print(\"Warning: No free models available - using local fallback mode\")\n",
        "else:\n",
        "    print(f\"Available models: {', '.join(bot.FREE_MODELS)}\")\n",
        "\n",
        "print(\"Type 'quit' to exit\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        response = bot.chat(user_input)\n",
        "\n",
        "        if bot.FREE_MODELS:\n",
        "            model = bot.FREE_MODELS[bot.current_model_index]\n",
        "            print(f\"Bot ({model}): {response}\")\n",
        "        else:\n",
        "            print(f\"Bot (local): {response}\")\n",
        "\n",
        "        # Cycle to next model for next request\n",
        "        if bot.FREE_MODELS:\n",
        "            bot.current_model_index = (bot.current_model_index + 1) % len(bot.FREE_MODELS)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF_u8Mk5COdn",
        "outputId": "2364797f-2443-42dc-92f1-0d3e9c4c3f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing chatbot...\n",
            "Available models: meta-llama/llama-2-13b-chat, huggingfaceh4/zephyr-7b-beta, mancer/weaver, google/palm-2-chat-bison\n",
            "Type 'quit' to exit\n",
            "You: hi\n",
            "Bot (meta-llama/llama-2-13b-chat): API Error: Insufficient credits. Add more using https://openrouter.ai/settings/credits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class FreeChatbot:\n",
        "    def __init__(self):\n",
        "        self.API_KEY = \"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\"  # Replace with your actual key\n",
        "        self.FREE_MODELS = [\n",
        "            \"huggingfaceh4/zephyr-7b-beta\",  # Completely free\n",
        "            \"meta-llama/llama-2-13b-chat\",   # Free tier\n",
        "            \"google/palm-2-chat-bison\",       # Free tier\n",
        "            \"mancer/weaver\"                  # Free tier\n",
        "        ]\n",
        "        self.current_model_index = 0\n",
        "        self.rate_limit = deque(maxlen=5)  # More conservative rate limiting\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        for attempt in range(len(self.FREE_MODELS)):\n",
        "            model = self.FREE_MODELS[self.current_model_index]\n",
        "\n",
        "            try:\n",
        "                # Rate limiting\n",
        "                now = time.time()\n",
        "                while len(self.rate_limit) >= 5 and now - self.rate_limit[0] < 10:\n",
        "                    time.sleep(1)\n",
        "                    now = time.time()\n",
        "\n",
        "                self.rate_limit.append(now)\n",
        "\n",
        "                response = requests.post(\n",
        "                    \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                    headers={\n",
        "                        \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                        \"HTTP-Referer\": \"https://localhost:3000\",  # Required\n",
        "                        \"X-Title\": \"Free Chat App\"                # Required\n",
        "                    },\n",
        "                    json={\n",
        "                        \"model\": model,\n",
        "                        \"messages\": [{\"role\": \"user\", \"content\": prompt}]  # No history to save credits\n",
        "                    },\n",
        "                    timeout=20\n",
        "                )\n",
        "\n",
        "                data = response.json()\n",
        "\n",
        "                if \"choices\" in data:\n",
        "                    return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                # If error contains \"credits\", skip to next model\n",
        "                if \"credits\" in str(data.get('error', {})):\n",
        "                    print(f\"Skipping {model} (requires credits)\")\n",
        "                    self.current_model_index = (self.current_model_index + 1) % len(self.FREE_MODELS)\n",
        "                    continue\n",
        "\n",
        "                return f\"API Error: {data.get('error', {}).get('message', 'Unknown error')}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {model}: {str(e)}\")\n",
        "\n",
        "            # Cycle to next model\n",
        "            self.current_model_index = (self.current_model_index + 1) % len(self.FREE_MODELS)\n",
        "\n",
        "        return \"All free models are currently unavailable. Please try again later.\"\n",
        "\n",
        "# Usage\n",
        "bot = FreeChatbot()\n",
        "print(\"Free Chatbot - Strictly No Credit Usage\")\n",
        "print(f\"Available models: {', '.join(bot.FREE_MODELS)}\")\n",
        "print(\"Type 'quit' to exit\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        response = bot.chat(user_input)\n",
        "        print(f\"Bot: {response}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0TkAXnHCpwl",
        "outputId": "0316eed7-1f93-4dce-ba37-b68880f0469f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free Chatbot - Strictly No Credit Usage\n",
            "Available models: huggingfaceh4/zephyr-7b-beta, meta-llama/llama-2-13b-chat, google/palm-2-chat-bison, mancer/weaver\n",
            "Type 'quit' to exit\n",
            "You: hi\n",
            "Bot: API Error: No endpoints found for huggingfaceh4/zephyr-7b-beta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from collections import deque\n",
        "import getpass\n",
        "\n",
        "class ColabChatbot:\n",
        "    def __init__(self):\n",
        "        # Secure API key input\n",
        "        self.API_KEY = getpass.getpass(\"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\")\n",
        "        self.FREE_MODELS = [\n",
        "            \"huggingfaceh4/zephyr-7b-beta\",  # Most reliable free option\n",
        "            \"microsoft/orca-2-13b\",           # Good alternative\n",
        "            \"gryphe/mythomax-l2-13b\",         # Another free option\n",
        "            \"meta-llama/llama-2-70b-chat\"     # Free for limited use\n",
        "        ]\n",
        "        self.current_model_index = 0\n",
        "        self.rate_limit = deque(maxlen=3)  # Conservative: 3 requests/10s\n",
        "        self.session_start = time.time()\n",
        "\n",
        "    def chat(self, prompt):\n",
        "        for attempt in range(len(self.FREE_MODELS)):\n",
        "            model = self.FREE_MODELS[self.current_model_index]\n",
        "\n",
        "            try:\n",
        "                # Rate limiting\n",
        "                while len(self.rate_limit) >= 3 and time.time() - self.rate_limit[0] < 10:\n",
        "                    time.sleep(1)\n",
        "\n",
        "                response = requests.post(\n",
        "                    \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                    headers={\n",
        "                        \"Authorization\": f\"Bearer {self.API_KEY}\",\n",
        "                        \"HTTP-Referer\": \"https://colab.research.google.com/\",\n",
        "                        \"X-Title\": \"Colab Chatbot\"\n",
        "                    },\n",
        "                    json={\n",
        "                        \"model\": model,\n",
        "                        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "                    },\n",
        "                    timeout=30\n",
        "                )\n",
        "\n",
        "                self.rate_limit.append(time.time())\n",
        "                data = response.json()\n",
        "\n",
        "                if \"choices\" in data:\n",
        "                    return data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                # Handle model-specific errors\n",
        "                error_msg = data.get('error', {}).get('message', '')\n",
        "                if \"credits\" in error_msg.lower():\n",
        "                    print(f\"Model {model} requires credits, trying next...\")\n",
        "                    self._next_model()\n",
        "                    continue\n",
        "\n",
        "                return f\"Error: {error_msg or 'Unknown error'}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {model}: {str(e)}\")\n",
        "                self._next_model()\n",
        "\n",
        "        return \"All free models are currently unavailable. Try again later or use different models.\"\n",
        "\n",
        "    def _next_model(self):\n",
        "        self.current_model_index = (self.current_model_index + 1) % len(self.FREE_MODELS)\n",
        "\n",
        "# Run in Colab\n",
        "print(\"Colab OpenRouter Chatbot - Free Models Only\")\n",
        "print(\"------------------------------------------\")\n",
        "bot = ColabChatbot()\n",
        "\n",
        "# Display model information\n",
        "print(f\"\\nAvailable Free Models:\")\n",
        "for i, model in enumerate(bot.FREE_MODELS, 1):\n",
        "    print(f\"{i}. {model}\")\n",
        "\n",
        "print(\"\\nChat session started. Type 'quit' to exit.\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "        response = bot.chat(user_input)\n",
        "        response_time = time.time() - start_time\n",
        "\n",
        "        print(f\"\\nBot [{bot.FREE_MODELS[bot.current_model_index]}]: {response}\")\n",
        "        print(f\"(Response time: {response_time:.2f}s)\")\n",
        "        print()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "\n",
        "print(\"\\nSession ended. Total duration:\", time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - bot.session_start)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkdtfbLHDJR7",
        "outputId": "9e45be8f-1e14-4f5e-b726-572dd94633d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab OpenRouter Chatbot - Free Models Only\n",
            "------------------------------------------\n",
            "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··········\n",
            "\n",
            "Available Free Models:\n",
            "1. huggingfaceh4/zephyr-7b-beta\n",
            "2. microsoft/orca-2-13b\n",
            "3. gryphe/mythomax-l2-13b\n",
            "4. meta-llama/llama-2-70b-chat\n",
            "\n",
            "Chat session started. Type 'quit' to exit.\n",
            "\n",
            "You: hi\n",
            "\n",
            "Bot [huggingfaceh4/zephyr-7b-beta]: Error: No auth credentials found\n",
            "(Response time: 0.07s)\n",
            "\n",
            "\n",
            "Session ended. Total duration: 00:02:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace with your actual OpenRouter API key\n",
        "OPENROUTER_API_KEY = \"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\"\n",
        "\n",
        "def chat_with_openrouter(prompt, model=\"google/palm-2-chat-bison\"):  # Using a free model\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "        \"X-Title\": \"Colab Chatbot (Free)\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json={\n",
        "                \"model\": model,  # Using a free model\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        else:\n",
        "            return f\"Error {response.status_code}: {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# List of free models you can use\n",
        "FREE_MODELS = [\n",
        "    \"google/palm-2-chat-bison\",  # Free\n",
        "    \"meta-llama/llama-2-13b-chat\",  # Free\n",
        "    \"gryphe/mythomax-l2-13b\",  # Free\n",
        "    \"nousresearch/nous-hermes-llama2-13b\",  # Free\n",
        "    \"openchat/openchat-7b\",  # Free\n",
        "]\n",
        "\n",
        "print(\"Free Chatbot ready! Type 'quit' to exit.\")\n",
        "print(f\"Available free models: {', '.join(FREE_MODELS)}\")\n",
        "\n",
        "current_model = FREE_MODELS[0]  # Start with the first free model\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    elif user_input.lower().startswith('/model '):\n",
        "        # Allow switching models\n",
        "        new_model = user_input[7:].strip()\n",
        "        if new_model in FREE_MODELS:\n",
        "            current_model = new_model\n",
        "            print(f\"Switched to model: {current_model}\")\n",
        "        else:\n",
        "            print(f\"Model not available in free tier. Choose from: {', '.join(FREE_MODELS)}\")\n",
        "        continue\n",
        "\n",
        "    response = chat_with_openrouter(user_input, model=current_model)\n",
        "    print(\"Bot:\", response)\n",
        "    print(f\"[Using model: {current_model}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "y2OK48XHFfLK",
        "outputId": "0c10ec27-8c6b-4943-bc9d-5c0bff840b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free Chatbot ready! Type 'quit' to exit.\n",
            "Available free models: google/palm-2-chat-bison, meta-llama/llama-2-13b-chat, gryphe/mythomax-l2-13b, nousresearch/nous-hermes-llama2-13b, openchat/openchat-7b\n",
            "You: hi\n",
            "Bot: Error 402: {\"error\":{\"message\":\"Insufficient credits. Add more using https://openrouter.ai/settings/credits\",\"code\":402}}\n",
            "[Using model: google/palm-2-chat-bison]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-fb85a5551a80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.router.ai/v1/ping\"  # Change this if needed\n",
        "headers = {\"Authorization\": \"Bearer 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\"}  # Replace with your key\n",
        "\n",
        "try:\n",
        "    response = requests.get(url, headers=headers)\n",
        "    print(response.status_code, response.text)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MKFKhtRF0nA",
        "outputId": "f9e9c7b8-2ebe-487b-89c8-b7fe5126fa63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: HTTPSConnectionPool(host='api.router.ai', port=443): Max retries exceeded with url: /v1/ping (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7c0b0e5c3cd0>: Failed to resolve 'api.router.ai' ([Errno -2] Name or service not known)\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"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\"  # Replace with your actual API key\n",
        "URL = \"https://api.router.ai/v1/ping\"  # Check Router AI's documentation for correct endpoint\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "\n",
        "try:\n",
        "    response = requests.get(URL, headers=headers)\n",
        "    print(\"Status Code:\", response.status_code)\n",
        "    print(\"Response:\", response.json())\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(\"Error:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaWVd4BUH9Uz",
        "outputId": "56b54777-6d3a-40c5-d659-47eec403f751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: HTTPSConnectionPool(host='api.router.ai', port=443): Max retries exceeded with url: /v1/ping (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7c0b0e5dff50>: Failed to resolve 'api.router.ai' ([Errno -2] Name or service not known)\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZDN7xBxKpwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}